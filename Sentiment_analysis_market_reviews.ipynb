{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Сентимент-анализ отзывов на товары\n",
    "\n",
    "**Соревнования Kaggle https://www.kaggle.com/c/product-reviews-sentiment-analysis **\n",
    "\n",
    "К вашей компании пришел заказчик, которому нужно решение задачи анализа тональности отзывов на товары. Заказчик хочет, чтобы вы оценили возможное качество работы такого алгоритма на небольшой тестовой выборке. При этом больше никаких данных вам не предоставляется."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку тестовая выборка маленькая, на ней обучать модель мы не можем, поэтому необходимо собрать отзывы на подобные товары с разметкой, и обучить модель на них. Сначала необходимо собрать отзывы для тренировки модели, которая будет классифицировать отзывы заказчика.  \n",
    "\n",
    "План работ будет следующий:   \n",
    "**1)** С помощью парсера собирать достаточное количество отзывов на подобные товары для тренировки модели.  \n",
    "**2)** Предварительно подготавить данные  \n",
    "**3)** Выбрать и обучить модель на собранных отзывах.  \n",
    "**4)** Сделать предсказание на тестовых данных  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Написание парсера. Сбор тренировочных данных  \n",
    "\n",
    "Импортируем необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ужасно слабый аккумулятор, это основной минус этого аппарата, разряжается буквально за пару часов при включенном wifi и на макс подсветке, например если играть или смотреть видео, следовательно использовать можно только если есть постоянная возможность подзарядиться. Качества звука через динамик далеко не на высоте.Наблюдаются незначительные тормоза в некоторых приложениях и вообще в меню. Очень мало встроенной памяти, а приложения устанавливаются именно туда, с этим связанны неудобства - нужно постоянно переносить их на карту памяти. Несколько неудобно что нету отдельной кнопки для фото. Подумываю купить батарею большей емкость мб что нибудь измениться.',\n",
       " 'ценанадежность-неубиваемостьдолго держит батарею 4 дня стабильно как телефон, 3-4 как плеер если  постоянно долбиться в уши и звонить по паре часо на дню, игры и, конечно,  смс , в месяц около 200 шт набирается.  Максимальное время работы 5 дней в щадящем режиме.2 simqwerty рулит -после нее набор смс на обычных сенсорниках и кнопочных -просто издивательствогромкий ,чистый звук (хорошо варьируется как в + так и в -)значение hot кнопок (верхняя панель до основной раскладки цифры/буквы) задается под себямного цветных панелек с пластиковым защитным  экраном,переставляются легко(те родной экран телефона никогда не поцарапается)кнопки не стираютсякак не странно достойные фото, нет не спорю не 25 мегапикселей, но  отснять рассписание или конспекты, зафотать пейзаж за окном автобуса получается вполне пристойносохранение файлов,отснятых фото, переброшенных песен происходит  на карту памяти  и это оч удобно, карточки кушает до 32 Гб !удобный ашевский бонус смс чат с аббанентом т.е.  вы можете видеть всю ветку беседы с конкретным человеком , а не искать в куче входящих смс с нужной информацией. работает чисто без галюнов,падал,шврялся,купался,используется как тел и плеер,в метро поездов не слышно уши юзаю сенхайзер 300 и 500,mp3 звонок чистый без сипов.Экран  не горилла глас , но на солнце сохраняет читаемость, в отличие от большинства  сенсорников , битых пикселей и засветов нет.Самсунговские кверти менее удобные ,пользовалась((( буква \"б\" и \" ь\"  просто убивают(((Нокиевская кверти интуитивно понятна и более дружелюбна к пользователю.Подстройка телефона под себя те вынос на экран нужных приложений, перемена значений у кнопок существенно облегчает жизнь.',\n",
       " 'подробнее в комментариях К сожалению, факт поломки через месяц использования сильно подпортил впечатление от телефона. Попытался установить языковое обновление - в итоге - экран смерти. Отдал в ремонт - сказали, что полетела материнская плата.  По сути месяц уже лежит в СЦ. Печальный опыт, больше HTC не куплю.']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_file = 'D:\\\\Python\\\\Kaggle\\\\Sent_an\\\\test.csv'\n",
    "with open(test_file,encoding=\"utf-8\") as f:\n",
    "    test = f.read()\n",
    "    \n",
    "test_page = BeautifulSoup(test, 'lxml')\n",
    "test_reviews = test_page.findAll('review')\n",
    "\n",
    "test_reviews_list = []\n",
    "for i in range(len(test_reviews)):\n",
    "    test_reviews_list += [test_reviews[i].text.replace('\\n',' ').strip()]\n",
    "    \n",
    "test_reviews_list[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из полученного списка видно, что это отзывы на мобильные телефоны. Соберем тренировочную выборку.\n",
    "Для этого будем парсить сайт https://torg.mail.ru/review/goods/mobilephones  \n",
    "Анализируем первую страницу с отзывами и определяем в каких блоках находится сами отзывы, а в каких оценки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'https://torg.mail.ru/review/goods/mobilephones/'\n",
    "req = requests.get(url)\n",
    "page =BeautifulSoup(req.text, 'lxml')\n",
    "# print(page.prettify()) - позволяет просмотреть код страницы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = []\n",
    "rating = []\n",
    "for i_page in range(0, 400):\n",
    "    url = 'https://torg.mail.ru/review/goods/mobilephones/?page=' + str(i_page)\n",
    "    req = requests.get(url)\n",
    "    soup = BeautifulSoup(req.text, 'lxml')\n",
    "    rev = soup.find('section', class_= \"card__responses js-review_list js-ustat_container js-ustat_container_reviewsList\").find_all('div', class_='review-item__body')\n",
    "    for r in rev:\n",
    "        review = r.find('span', class_='js-more-text').text.strip()\n",
    "        mark = r.find('span', class_='review-item__rating-counter').text.strip().replace(\",\",\".\")\n",
    "        texts.append(review)\n",
    "        rating.append(float(mark))       \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "print(len(texts))\n",
    "print(len(rating))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и ожидалось количество отзывов 8000.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним данные в csv файл, для последующего использования "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mail_reviews = pd.DataFrame()\n",
    "mail_reviews['text'] = texts\n",
    "mail_reviews['rating'] = rating\n",
    "mail_reviews.to_csv(r'D:\\Python\\Kaggle\\Sent_an\\mail_reviews.csv', encoding='utf-8', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'D:\\Python\\Kaggle\\Sent_an\\mail_reviews.csv', sep=',')\n",
    "texts = data['text'].tolist()\n",
    "rating = data['rating'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отзывы с оценкой 4.5 и выше примем за положительные 'pos', остальные негативные 'neg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rating2 = []\n",
    "for r in rating:\n",
    "    if  r >= 4.5:\n",
    "        rating2.append('pos')\n",
    "    else:\n",
    "        rating2.append('neg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчитаем сколько положительных и отрицательных отзывов в полученной выборке, для этого воспользуемся встроенным классом Counter из модуля collections:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'neg': 3415, 'pos': 4585})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "c = Counter(rating2)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что полученная выборка несбалансированная, это следует учитывать при построении модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Предварительная подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pymorphy2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приведем буквы к нижнему регистру, оставим в тексте только русские буквы и проведем леммитизацию, для этого напишем функцию lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatization(data):\n",
    "    reg = re.compile('[^абвгдеёжзийклмнопрстуфхцчшщъыьэюя ]')\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    texts_clean = []\n",
    "    for i in data:\n",
    "        a = i.lower()\n",
    "        b = reg.sub('', a)\n",
    "        result = []\n",
    "        for word in b.split():\n",
    "            result.append(morph.parse(word)[0].normal_form)\n",
    "            c = ' '.join(result)\n",
    "        texts_clean.append(c)\n",
    "    return (texts_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_clean = lemmatization(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Выбираем и обучаем модель на собранных отзывах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vera\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = CountVectorizer(ngram_range=(2,4), min_df = 5,  analyzer='word')\n",
    "X_train = cv.fit_transform(texts_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберем модель с наилучшей предсказательной способностью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.639125\n",
      "<class 'sklearn.naive_bayes.MultinomialNB'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\Vera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\Vera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\Vera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\Vera\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = 0\n",
    "best_clf = 0\n",
    "for clf in [LogisticRegression, LinearSVC, SGDClassifier, MultinomialNB]:\n",
    "    model = clf()\n",
    "    accuracy = cross_val_score(model, X_train, rating2, cv = 5).mean()\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_clf = clf\n",
    "        \n",
    "        \n",
    "print(best_accuracy)\n",
    "print(best_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По кросс - валидации лучшая модель - MultinomialNB.\n",
    "Однако попробуем сдалать предсказание, используя Логистическую регрессию, но с балансировкой классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.61587499999999995"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(class_weight='balanced', random_state = 2) \n",
    "clf.fit(X_train, rating2)\n",
    "accuracy = cross_val_score(clf, X_train, rating2, cv = 5).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что точность по кросс - валидации снизилась"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем задать другой критерий деления на положительные и отрицательные отзывы. На этот раз к положительным отнесем отзывы с оценкой 4 и выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'neg': 2144, 'pos': 5856})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating3 = []\n",
    "for r in rating:\n",
    "    if  r >= 4.0:\n",
    "        rating3.append('pos')\n",
    "    else:\n",
    "        rating3.append('neg')\n",
    "        \n",
    "from collections import Counter\n",
    "c = Counter(rating3)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выборка стала еще более несбалансирована  \n",
    "Построим модель и сделаем предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72999402187266471"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB() \n",
    "clf.fit(X_train, rating3)\n",
    "accuracy = cross_val_score(clf, X_train, rating3, cv = 5).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим что точность по кросс - валидации заметно повысилась с 0,64 до 0,73  \n",
    "Подготовим тестовые данные и сделаем предсказание "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_lemm = lemmatization(test_reviews_list)\n",
    "X_test = cv.transform(test_lemm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df  = pd.DataFrame(prediction)\n",
    "df.index.name = 'Id'\n",
    "df.columns = ['y']\n",
    "df.to_csv(r'D:\\Python\\Kaggle\\Sent_an\\submission4.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точность на Kaggle получилась 0,76"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для улучшения предсказания попробуем еще поработать с выборкой:    \n",
    "поскольку отзывы с оценкой 4, всегда давольно неопределенные, т.е. вроде телефон понравилься, но однако есть что то, что мещает поставить 5, и вполне возможно именно об этой детали и описано в отзыве. Поскольку у нас имеется достаточно большая выбрка, можем удалить отзывы с оценкой 4 и посмотеть как это повлияет на качество модели. К тому же это сделает выборку более сбалансированной\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0    3905\n",
       "4.0    1271\n",
       "1.0     877\n",
       "4.5     680\n",
       "3.0     659\n",
       "2.0     285\n",
       "3.5     197\n",
       "2.5      89\n",
       "1.5      34\n",
       "0.0       3\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_clean = data[data['rating']!=4.0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То же может касаться и отзывов с оценкой 4.5, поэтому удалим и их из выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_clean = data_clean[data_clean['rating']!=4.5]\n",
    "texts = data_clean['text'].tolist()\n",
    "rating = data_clean['rating'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'neg': 2144, 'pos': 3905})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rating4 = []\n",
    "for r in rating:\n",
    "    if  r == 5.0:\n",
    "        rating4.append('pos')\n",
    "    else:\n",
    "        rating4.append('neg')\n",
    "        \n",
    "from collections import Counter\n",
    "c = Counter(rating4)\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что количество положительных отзывов сократилось, хотя выборка осталась несбалансированной  \n",
    "Применим нашу модель к новой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_clean = lemmatization(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71830158111683029"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = CountVectorizer(ngram_range=(2,4), min_df = 5,  analyzer='word')\n",
    "X_train = cv.fit_transform(texts_clean)\n",
    "clf = MultinomialNB() \n",
    "clf.fit(X_train, rating4)\n",
    "accuracy = cross_val_score(clf, X_train, rating4, cv = 5).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество по кросс - валидации немного снизилось.\n",
    "Однако обобщающая спосбность модели, должна улучшиться. Поэтому сделаем предсказание и проверим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_lemm = lemmatization(test_reviews_list)\n",
    "X_test = cv.transform(test_lemm)\n",
    "prediction = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df  = pd.DataFrame(prediction)\n",
    "df.index.name = 'Id'\n",
    "df.columns = ['y']\n",
    "df.to_csv(r'D:\\Python\\Kaggle\\Sent_an\\submission.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили точность на Kaggle 0,80, это немного лучше. Поработаем еще с данными и вместо лемматизации будем использовать Cтемминг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишем функцию для чистки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cleaning(data):\n",
    "    reg = re.compile('[^абвгдеёжзийклмнопрстуфхцчшщъыьэюя ]')\n",
    "    data_clean = []\n",
    "    for i in data:\n",
    "        a = i.lower()\n",
    "        b = reg.sub('', a)\n",
    "        data_clean.append(b)\n",
    "    return(data_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts_clean_for_stem = cleaning(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6049x323552 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 375665 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "analyzer = CountVectorizer(ngram_range=(2,4), min_df=5, analyzer = 'word' ).build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    return (stemmer.stem(w) for w in analyzer(doc))\n",
    "\n",
    "\n",
    "stem_vectorizer = CountVectorizer(analyzer=stemmed_words)\n",
    "vec_stem = stem_vectorizer.fit(texts_clean_for_stem)\n",
    "X_train_stem = vec_stem.transform(texts_clean_for_stem)\n",
    "X_train_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71830158111683029"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB() \n",
    "clf.fit(X_train_stem, rating4)\n",
    "accuracy = cross_val_score(clf, X_train, rating4, cv = 5).mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stem = cleaning(test_reviews_list)\n",
    "X_test = vec_stem.transform(test_stem)\n",
    "prediction = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(prediction)\n",
    "df2.index.name = 'Id'\n",
    "df2.columns = ['y']\n",
    "df2.to_csv(r'D:\\Python\\Kaggle\\Sent_an\\submission2.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество на Kaggle улучшилось и составило 0,82, т.е. наша модель даст правильный ответ в 82% случаев, что довольно неплохо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод: \n",
    "Для предсказания тональности отзыва были использованы 2 модели: LogisticRegression и MultinomialNB. Во всех случаях метод Байса показал наилучший результат. Результаты работы показывают, что подготовка и чистка данных является одним из наиболее важных этапов проведения анализа. Видно, что точность предсказания по кросс - валидации поднялась на ~10%, при изменении критерия разбиения отзывов на положительные и отрицательные. Точность предсказания на Kaggle поднялась на 5% после исключения отзывов которые с большой долей вероятности могут быть отнесены как к положительным, так и отрицательным. Еще на 2% удалось поднять точность при использовании стемминга вместо лемматизации. Можно и дальше повышать точность модели и добиться точности на Kaggle близкой к 100%, однако всегда надо помнить об опасности переобучения."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
